<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2022</h1>
<h1 align="middle">Project 3</h1>
<h2 align="middle">Jasmine Wang, 3034027325</h2>
<h2 align="middle">Victor Ho, 3033712816</h2>
<h2 align="middle">website link:</h2>
 <a href="https://cal-cs184-student.github.io/sp22-project-webpages-jwang99/proj2/index.html">https://cal-cs184-student.github.io/sp22-project-webpages-jwang99/proj2/index.html</a>

<br><br>

<h1 align="middle">Assignment 3: PathTracer</h1>
    <h2 align="middle">Your Name</h2>

    <div class="padded">
        <p>In this Project, we created the foundation for shading and coloring objects in a lit scene through ray tracing. We first established the basic tools such as detecting intersection with primitives, mapping world points to pixel locations, and building a BVH datastructure that makes intersection detection more efficient. Then we implemented progressively more complex illumination schemes starting with direct (zero and single bounce) lighting and eventually incorporating indirect (atleast one bounce) illumination, which used the primitives previously established to determine the proper illumination for pixels representing different points in a scene. Finally, we added an algorithm to speedup the rendering process of these scenes by establishing a "sampled enough" heuristic through adaptive sampling</p>

    <h2 align="middle">Part 1: Ray Generation and Scene Intersection: </h2>

    	<h3>Ray generation and primitve intersections</h3>
    	<p>Ray generation and primitive intersection is the first step in the rendering pipeline. In order for a camera to be able to render an image of what a 3D scene looks like, it must determine what should be represented in each pixel of the image. To do so, a transfomration is first established between the camera's image (normalized image coordinates) and the camera's virtual sensor (world frame coordinates), a plane orthogonal to the camera's direction. Then, we create a ray in the the world frame, from the cameras location, to the point in the world frame which corresponds to the location of that pixel. This ray represents the "viewing direction" for the objects that should be seen in the pixel. This process is known as ray generation.</p>
    	<p>Once the appropriate ray has been generated, to properly determine what color or object should appear in the image at each image coordinate, just follow along the direction of the ray until it intersects an object primitive (triangle, sphere, etc) that is used to build objects in the scene. Once an intersection is detected, the color of the image coordinate, should be dependent on the illuminance of the object in reverse direction of the ray.</p>

    	<h3>Triangle Intersection Algorithm</h3>
    	<p>My triangle-ray intersection algorithm is primarily built off of the Moller Trumbore Algorithm. Using the Moller Trumbore Algorithm on the triangle-ray pair that we are finding an intersection for, we get the values t (time of intersection), b1, and b2 (two of the 3 barycentric coordinates for the triangle). We first inspect the t value to make sure that it is within the lifespan of the ray (between t_min and t_max), since rays are considered as finite segments of the entire ray. Then we check the barycentric coordinates b0 = 1-b1-b2, b1, and b2 returned by the Moller Trumbore Algorithm to make sure that they represent a point that is actually INSIDE the triangle, meaning that all barycentric coordinates are between 0 and 1. If both conditions are true, the intersection is within the lifespan of the ray and the intersection point is inside the triangle, then there is an intersection between the given ray and triangle. </p>

    	<h3>Example images with normal shading for a few small .dae files</h3>

    	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part1/CBEmpty.png" width="480px" />
                    <figcaption align="middle">CBEmpty.dae renderred with normal shading</figcaption>
                </tr>
            </table>
        </div>

        <br><br><br>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part1/CBSpheres.png" width="480px" />
                    <figcaption align="middle">CBSpheres_lambertian.dae renderred with normal shading</figcaption>
                </tr>
            </table>
        </div>

    <br><br><br><br>
    <h2 align="middle">Part 2: Bounding Volume Hierarchy: </h2>
    	<h3>BVH Construction Algorithm</h3>
    	<p>The Construction of a Bounding Volume Hierarchy is a recursive process, where the BVH itself is a tree structure of BVH Nodes. When given a list of primitives that we are trying to segment into separate bounding volumes, if the number of primitives in this list is small enough to be contained in a single leaf node, then allocate a leaf node and the process is finished. Otherwise, if the number of primitives is too large to be contained in a single leaf node, we need to divide the primitives in half and create a sub-BVH tree for each half. The way that the primitives are allocated into 2 groups is: determine which axis (x, y, z) has the widest range in which primitives exist, and find the midpoint of this range. All primitives whose centroid is on one side of this midpoint gets put into one group, and all primitives whose centroid is on the other side is put into the other group. If there arises a situation in which one of these 2 groups has no primitives, forcibly move one primitve from the other group into this group.
    	<h3>Example images with normal shading for a few large .dae files using BVH acceleration</h3>

    	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/banana.png" width="480px" />
                    <figcaption align="middle">banana.dae renderred with normal shading</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/cow.png" width="480px" />
                    <figcaption align="middle">cow.dae renderred with normal shading</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/maxplanck.png" width="480px" />
                    <figcaption align="middle">maxplanck.dae renderred with normal shading</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/CBlucy.png" width="480px" />
                    <figcaption align="middle">CBlucy.dae renderred with normal shading</figcaption>
                </tr>
            </table>
        </div>

    	<h3>Render Time Comparison on Complex Geometries With and Without BVH acceleration</h3>
    	<p>Rendering time for complex geometries decreased SUBSTANTIALLY when BVH acceleration was used. This is because we no longer have to check for intersection between each ray and EVERY SINGLE primitive in the scene we are trying to render. For complex geometries like maxplanck.dae and CBlucy.dae, these contain over 50,000 and 130,000 primitives respectively. To do a linear search for intersection with each primitive for each ray would take incredibly long. When BVH acceleration is used, not only can we first check for possible intersection with a collection of primitives by using BBox-es that envelop multiple primitives, but due to the tree structure of the BVH, we can cut down the search space of our intersetion in half with every recursive call leading to significantly improved performance. These performance improvements can be seen in the render time comparisons of the following scenes with and without BVH acceleration. Notice that CBlucy.dae was not attempted without BVH acceleration because maxplanck already couldn't finish renderring within 2 minutes despite being able to finish in .06 seconds with BVH acceleration</p>

    	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_noBVH/banana.png" width="480px" />
                    <figcaption align="middle">banana.dae renderred in 21 seconds with normal shading WITHOUT BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_noBVH/cow.png" width="480px" />
                    <figcaption align="middle">cow.dae renderred in 34 seconds with normal shading WITHOUT BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_noBVH/maxplanck.png" width="480px" />
                    <figcaption align="middle">the progress made in 2 minutes to render maxplanck.dae with normal shading WITHOUT BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_withBVH/banana.png" width="480px" />
                    <figcaption align="middle">banana.dae renderred in 0.14 seconds with normal shading WITH BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_withBVH/cow.png" width="480px" />
                    <figcaption align="middle">cow.dae renderred in 0.04 seconds with normal shading WITH BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_withBVH/maxplanck.png" width="480px" />
                    <figcaption align="middle">maxplanck.dae renderred in 0.06 seconds with normal shading WITH BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2/rendertime_withBVH/CBlucy.png" width="480px" />
                    <figcaption align="middle">CBlucy.dae renderred in 0.05 seconds with normal shading WITH BVH acceleration</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>

        <p>Describe what you did in Part 1. etc...</p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part1/CBEmpty.png" width="480px" />
                    <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
                </tr>
            </table>
        </div>
        <p>Here is an example of how to include a simple formula:</p>
        <p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
        <p>or, alternatively, you can include an SVG image of a LaTex formula.</p>
        <p>This time it's your job to copy-paste in the rest of the sections :)</p>
  
  
  
  
  
   <h2 align="middle">Part 5: Adaptive Sampling: </h2>
    	<h3>Adaptive Sampling Implementation</h3>
      <p>To implement adaptive sampling, we used the algorithm described in the spec. Instead of the previous implementation of a fixed n samples per pixel, we terminate sampling when a function of the variance of the samples, number of samples, and mean of the samples has been fulfilled. Once our samples have converged to the desired degree, we stop sampling.</p>
      <p>We define two more variables, s1 and s2, to help us check after each sample if we have converged enough to stop sampling. We store in s1 a running sum of all of the illuminance values of the samples, and we store in s2 a running sum of the square of the illuminance values of the samples.
        From these two values, we can calculate our mean and variance of our samples so far: the mean is defined as s1 divided by the number of samples, and the variance is defined as sqrt((1/(n-1)) * (s2 - s1**2/n)), where n is our number of samples. From these statistics, we can calculate our heuristic value I, which is defined as 1.96 * variance / sqrt(numsamples).
        We want to terminate sampling when I <= maxtolerance * mean, where maxtolerance is a hyperparamter (0.05 by default.) For efficiency, we only calculate the heuristic once every numsamplesperbatch samples, where numsamplesberpatch is a hyperparameter (default 32), and terminate sampling once this check passes or we reach the maximum allowed number of samples.</p>
    	<h3>Example images showing the image rendered using adaptive sampling as well as the sample rate image, where red signifies the highest sampling rate and blue signifies the lowest sampling rate.</h3>

    	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part5/bunny.png" width="480px" />
                    <figcaption align="middle">bunny rendered with adaptive sampling</figcaption>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part5/bunny_rate.png" width="480px" />
                    <figcaption align="middle">sampling rates of bunny sampled with adaptive sampling</figcaption>
                </tr>
            </table>
        </div>


        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part5/dragon_adaptive.png" width="480px" />
                    <figcaption align="middle">dragon rendered with adaptive sampling<</figcaption>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part5/dragon_adaptive_rate.png" width="480px" />
                    <figcaption align="middle">sampling rates of dragon sampled with adaptive sampling<</figcaption>
                </tr>
            </table>
        </div>
        <br><br><br>
       
        
              <p>We see here that the shadows and darker areas have significantly higher sampling rates than those in direct light. This is because for these areas, the variance in the samples was much higher. This is also why these areas were much noisier without adaptive sampling. Thus, using this heuristic, we naturally sample noisier areas more</p>


    	


    <h2 align="middle">A Few Notes On Webpages</h2>
        <p>Here are a few problems students have encountered in the past. You will probably encounter these problems at some point, so don't wait until right before the deadline to check that everything is working. Test your website on the instructional machines early!</p>
        <ul>
        <li>Your main report page should be called index.html.</li>
        <li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
        <li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
        Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
        <li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre>
        <li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
        <li>And again, test your website on the instructional machines early!</li>
</div>
</body>
</html>




